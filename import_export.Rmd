---
title: "載入與寫出資料"
author: 郭耀仁
output: 
  revealjs::revealjs_presentation:
    theme: black
    highlight: zenburn
    center: true
---

# 載入資料

## csv

- 使用 `read.csv()` 函數

```{r eval=FALSE}
csv_file_path <- "Your csv file path"
df <- read.csv(csv_file_path)
```

## txt

- 使用 `read.table()` 函數

```{r eval=FALSE}
txt_file_path <- "Your text file path"
df <- read.table(txt_file_path, sep = "Text file separator", header = TRUE)
```

## excel

- 使用 `readxl::read_excel()` 函數
- 僅能讀取本機端的 Excel 試算表

```{r eval=FALSE}
install.packages("readxl")
library(readxl)

xlsx_file_path <- "Your excel file path"
df <- read_excel(xlsx_file_path)
```

## JSON

- 使用 `jsonlite::fromJSON()` 函數

```{r eval=FALSE}
install.packages("jsonlite")
library(jsonlite)

json_file_path <- "Your json file path"
data_list <- fromJSON(json_file_path)
```

# 寫出資料

## 寫出為 csv

```{r eval=FALSE}
write.csv(your_df, file = "Your csv file path")
```

## 寫出為 json

```{r eval=FALSE}
json_txt <- toJSON(your_list)
write(json_txt, file = "Your json file path")
```

# 網站資料來源

## 關於網站資料

- 內部資料庫不一定有表格欄位
- 外部資料庫要價昂貴
- 資料就像衣櫃中的衣服，永遠少一件？
- 能自動就不要手動

## 核心問題只有兩個

- 獲取網站的回應（request）
- 解析網站的回應（parser）

## R 語言相對於 Python 的爬蟲程式？

IMHO：在**靜態網頁**佔盡上風！

## 佔盡上風的原因是？

- Python 的 request 與 parser 仰賴不同的模組
- Python 的 `BeautifulSoup` 對 CSS 選擇器支援有限
- Python 的 `BeautifulSoup` 不支援 XPath 選擇器

## 網站擷取範例

- Yahoo! 奇摩股市
- Google Finance
- 批踢踢實業坊